---
title: 'A Unified Power Analysis of Association Tests'
# author: "GAO Zheng"
date: "April 5, 2019"
bibliography: bibliography.bib
output:
  html_document:
    theme: cosmo
    toc: yes
    toc_depth: 2
    toc_float: 
      collapsed: false
---

<!-- <style type="text/css"> -->

<!-- body{ /* Normal  */ -->
<!--       font-size: 18px; -->
<!--   } -->
<!-- </style> -->

```{r setup, echo=FALSE}
library(kableExtra)
```

In genetic association studies, researchers have the freedom to choose his/her favorite statistical procedure to perform hypothesis testing on the data collected.
In this document, we investigate the natural question: does the choice of statistical test influence the power of scientific discovery?

Perhaps unsurprisingly, the answer is (asymptotically) no.
We shall quantify this common power limit, and provide practical formulas for power calculations.

We recommend users review [the role played by disease models](disease_models_revisited.html){target="_blank"} before proceeding. 

# Unified asymptotic power analysis {#sec:unified-analysis}

In association studies for qualitative traits, counts of subjects in each phenotype-genetic variant combination are tabulated in the form of a contingency table.
For a 2-allele-variant-by-2-phenotype definition, we have the following table of counts.

```{r echo=FALSE}
dt <- data.frame(matrix(c("Cases", "$O_{11}$", "$O_{12}$", "$n_1$",
                          "Controls", "$O_{21}$", "$O_{22}$", "$n_2$"), byrow = T, nrow = 2))

colnames(dt) <- c("# Observations", "Variant 1", "Variant 2", "Counts by phenotype")

kable(dt, "html", escape = FALSE, align = "c") %>%
  kable_styling(bootstrap_options = c("hover", "responsive"), full_width = F) %>%
  add_header_above(c(" " = 1, "Allele variant" = 2, " " = 1))
```

Statistics are then calculated based on the counts, to test for associations between the genotypes and phenotypes, at levels adjusted for multiplicity.
Performance of a test is measured in terms of power, i.e., probability of correct rejection under an alternative hypothesis.

Power analysis starts by assuming an alternative distribution, typically (though not necessarily) described by a disease model.
Power of a test is approximated either based on large sample asymptotics, or by simulating the empirical distribution of the statistic under the alternative.

<!--
Note that even when the disease model dictates more than two genotypes (e.g., one heterozygous and two homozygous variants in an additive model), the association tests may still be based on only two derived variants.
This can be due to either grouping of the genotypes definitions in dominant or recessive models, or by adopting a direct comparison of the proportions of allele types between the Case and Control groups, as opposed to the proportions of zygosity.
Indeed, the latter approach is the basis of power calculations in @skol2006joint.
-->

## A model-invariant parametrization {#subsec:model-invariant}

<!--
Test statistics are calculated based on cell counts of the contingency table.
The alternative hypothesis, consequently, influences the distribution of the test statistics only through altering the distribution of the multinomial integer counts in the contingency tables.
-->

Consider 2-by-2 multinomial distributions with probability matrix $\mu = (\mu_{ij})_{2\times2}$,

```{r echo=FALSE}
dt <- data.frame(matrix(c("Cases", "$\\mu_{11}$", "$\\mu_{12}$", "$\\phi = \\mu_{11} + \\mu_{12}$",
                          "Controls", "$\\mu_{21}$", "$\\mu_{22}$", "$1-\\phi = \\mu_{21} + \\mu_{22}$"), byrow = T, nrow = 2))

colnames(dt) <- c("Probabilities", "Variant 1", "Variant 2", "Total by phenotype")

kable(dt, "html", escape = FALSE, align = "c") %>%
  kable_styling(bootstrap_options = c("hover", "responsive"), full_width = F) %>%
  add_header_above(c(" " = 1, "Allele variant" = 2, " " = 1))
```

We may assume -- by relabelling, and hence without loss of generality -- that genetic Variant 1 is positively associated with the Cases, and referred to as the risk allele / variant. 
The multinomial probability matrix $\mu$ can be fully parametrized by the parameter triple (explicit expressions are given at the end of the section):

* Fraction of Cases $\phi$, i.e., marginal distribution of phenotypes.

* Conditional distribution of risk variant among Controls, i.e., risk allele frequency (RAF) in the Control group 
$$
    f := \mu_{21}\big/(1-\phi),
$$
* Odds ratio (OR) of the genotype Variant 1 to Variant 2
$$
\text{R} := \frac{\mu_{11}}{\mu_{21}}\Big/\frac{\mu_{12}}{\mu_{22}} = \frac{\mu_{11}\mu_{22}}{\mu_{12}\mu_{21}}.
$$

An alternative hypothesis, e.g., a disease model, determines the canonical parameters $(f, R)$ implicitly,
%The fraction of Cases $\phi$ is part of the study design.
and therefore fully determines statistical power for a specific test at given sample sizes.
Alternatively, power can also be calculated by directly prescribing the canonical parameters and the sample sizes.
(See, again, [Disease Models Revisited](disease_models_revisited.html){target="_blank"}.)

It is worth pointing out that while disease models play no role beyond specifying the alternative, they do sometimes inform our choice of a test statistic, hence influencing statistical power in higher order contingency tables.
These tests include, e.g., the Cochran-Armitage test, and variations thereof;
see @gonzalez2008maximizing, @li2008efficient, for further examples where tests are tailored to disease models. 

We make the important distinction between RAF **in the Control group** ($f$), versus RAF **in the study** ($\mu_{11}+\mu_{21}$), and RAF **in the general population**.
In the following sections, unless otherwise stated, RAF will refer to the risk allele frequency in the Control group, consistent with the reporting standards of the NHGRI-EBI Catalog [@macarthur2016new].

## Conditional vs unconditional tests {#subsec:conditional}

Readers familiar with the underlying assumptions of association tests in contingency tables may have noticed that we have described a multinomial distribution of the cell counts.
That is, we have only conditioned on the total number of observations in the study.
This is indeed the assumption behind tests such as (the original, unconditional version of) the likelihood ratio test, and the Person chi-square test.

It is not, however, the assumption behind some other tests.
For example, analysis of t-tests typically assumes the observed number in each arm of the study are given.
That is, we would condition on the phenotype marginals when comparing the proportions of genetic variants among the Cases and Controls.
It is perhaps an assumption most close to reality, where the number of samples collected in each arm of the study are pre-determined.
In this case, we have two binomial observations, Binom$(n_1, p_1)$ and Binom$(n_2, p_2)$, instead of a multinomial observation.
```{r echo=FALSE}
dt <- data.frame(matrix(c("Cases", "$p_{1}$", "$1-p_{1}$", "$n_1$",
                          "Controls", "$p_{2}$", "$1-p_{2}$", "$n_2$"), byrow = T, nrow = 2))

colnames(dt) <- c("Cond. Prob.", "Risk allele", "Non-risk allele", "Counts by phenotype")

kable(dt, "html", escape = FALSE, align = "c") %>%
  kable_styling(bootstrap_options = c("hover", "responsive"), full_width = F) %>%
  add_header_above(c(" " = 1, "Allele variant" = 2, " " = 1))
```

RAF and OR can be similarly defined,

* the marginal distribution of Cases is fixed at $\phi := n_1/(n_1+n_2)$,

* the risk allele frequency (RAF) in the Control group is the synonymous with the conditional distribution of risk variant among Controls, 
$$
f := p_2,
$$
* and the odds ratio (OR) is
$$
\text{R} := \frac{p_{1}\phi}{p_{2}(1-\phi)}\Big/\frac{(1-p_{1})\phi}{(1-p_{2})(1-\phi)} = \frac{p_{1}(1-p_{2})}{(1-p_{1})p_{2}}.
$$

Alternative hypotheses may be formed as in the multinomial case with parameters $\phi$, $f$ and $R$, along with the total samples size.

Finally, we mention the assumptions behind the Fisher's exact test.
The Fisher exact test conditions on the number of observations of both the phenotype variants and genetic variants, leading to a hypergeometric distribution of the first cell count $O_{11}$ given the marginals $n_1$, $n_2$, and $O_{11}+O_{21}$, under the null hypothesis.
We found no easy parametrizations of alternative hypotheses under this framework.
Indeed, existing power calculations for Fisher's exact test resort to simulations under the two-binomial assumptions [@smyth2017].

We refer interested readers to the recent work by @ripamonti2017contemporary and @choi2015elucidating which elucidate the controversies regarding the choices of conditioning when performing statistical inferences on 2-by-2 contingency tables.
We do not attempt to resolve the controversies in this work.
Our goal is to state clearly the assumptions behind the tests, and show the asymptotic equivalence in terms of power, under their respective assumptions.

## A test-independent power analysis {#subsec:power-calculation}

We now present the main result allowing a unified power analysis, applicable for a wide range of common association tests in 2-by-2 tables.

If we consider a fixed parameter values of $(f, R)$ under the alternative, no matter how close to the null, the probability of rejection of the null hypothesis by any reasonable test should approach one as sample size increases ($n\to\infty$).
On the other hand, the probability of rejection is less than one in finite samples, making this type of asymptotics useless for approximation.

Therefore, in order to find finer approximations of power, we study alternatives close to the null.
In particular, we take a sequence of alternatives approaching a limit point in the null space, in the hope that limiting rejection probability is between 0 and 1.
It turns out -- see, e.g., @ferguson2017course Chapter 10, and @lehmann2004elements Chapter 5 -- that the appropriate rate at which the alternatives should shrink towards the limit point is $1/\sqrt{n}$. 
<!-- % and the appropriate limit point is the maximum likelihood estimate (MLE) of the probabilities under the null hypothesis (which happens to coincide with the minimum chi-square estimates). -->

Under the multinomial assumption, let $\mu^{(0)}$ be the probability matrix of the (independent) 2-by-2 multinomial distribution, with marginals $(\theta, 1-\theta)$ for the genetic variants, and marginals $(\phi, 1-\phi)$ for the phenotypes.
We require that $\theta\in(0,1)$ and $\phi\in(0,1)$ be bounded away from 0 and 1.
Let $\mu = \mu^{(n)}$ be the sequence of alternatives such that 
\begin{equation} \label{eq:alternative-multinomial}
    \sqrt{n}(\mu^{(0)} - \mu^{(0)}) \rightarrow \delta \begin{pmatrix} 1 & -1 \\ -1 & 1 \end{pmatrix},
\end{equation}
where $\delta$ is a positive constant.

Similarly, under the two-binomial assumption, let $p_1^{(0)} = p_2^{(0)} = \theta$ be the null hypothesis, with fixed marginals $(\phi, 1-\phi)$ for the phenotypes.
Let $(p_1, p_2) = p^{(n)}$ be the sequence of alternatives such that 
\begin{equation} \label{eq:alternative-two-bionomial}
    \sqrt{n}\phi (p_1-\theta) \rightarrow \delta
    \quad \text{and} \quad 
    \sqrt{n}(1-\phi) (p_2-\theta) \rightarrow -\delta,
\end{equation}
where $\delta$ is a positive constant.
It is easy to see that with the same $\delta$ the two sequences of alternatives have the same RAF and OR, and therefore have the same expected number of observations in each cell.

  
<div class="panel panel-primary">
<div class="panel-heading"> Theorem 1 </div>
<div class="panel-body">
In 2-by-2 contingency tables, under the assumption that the counts in the contingency table follow the multinomial distributions, 
    
* the likelihood ratio test for independence,
* the likelihood ratio test for zero slope in logistic regressions,
* Person's chi-squared test for Independence,

and under the assumption that counts in the contingency table follow the two binomial distributions, 

* the two-sided Welch's t-test for equal proportions 
    
have the same asymptotic power curves.
Specifically, for the sequence of alternatives defined above, all of the listed tests, at level $\alpha$, have statistical powers converging to 
\begin{equation} \label{eq:power-approx}
    \mathbb P[\chi^2(\lambda) \ge q_{\alpha}],
\end{equation}
where $q_{\alpha}$ is the upper $\alpha$ quantile of the central chi-square distribution, and $\chi^2(\lambda)$ is a non-central chi-square distribution with non-centrality parameter
\begin{equation} \label{eq:non-centrality}
    \lambda = \delta^2/{(\theta(1-\theta)\phi(1-\phi))}.
\end{equation}
  </div>
</div>

The proof of Theorem 1 is detailed in [Section 3](#sec:proof).

Theorem 1 is the central result that paves the way for a unified power analysis.
It allows us to chart findings from different studies employing the applicable tests in the same diagram, with the same power limits.
In particular, for large samples, tests for zero slopes in logistic regressions should report approximately the same set of loci as Welch's t-tests for equal proportions on the same dataset, after the same family-wise error rate adjustments.
The estimated odds ratios (in the case of logistic regression, estimate slopes exponentiated) and RAF's, when charted on the OR-RAF diagram, should also follow the same power limits.

To use this result for power calculations, we start with an alternative hypothesis, defined by the canonical parameters $(f, R)$, and sample sizes $(\phi, n)$.
```{r echo=FALSE}
dt <- data.frame(matrix(c("Cases", "$\\frac{fR\\phi}{(fR+1-f)}$", "$\\frac{(1-f)\\phi}{(fR+1-f)}$",  "$\\phi$",
                          "Controls", "$f(1-\\phi)$", "$(1-f)(1-\\phi)$",  "$1-\\phi$"), byrow = T, nrow = 2))

colnames(dt) <- c("Probabilities", "Risk allele", "Non-risk allele", "Total by phenotype")

kable(dt, "html", escape = FALSE, align = "c") %>%
  kable_styling(bootstrap_options = c("hover", "responsive"), full_width = F) %>%
  add_header_above(c(" " = 1, "Allele variant" = 2, " " = 1))
```

Elementary algebra yields 
$$\theta = \frac{fR\phi}{(fR+1-f)} + f(1-\phi),$$ 
and 
$$\delta = \sqrt{n}(\theta - f)(1-\phi).$$
If tests are based on allele type counts, accounting for the fact that each genetic location has a pair of alleles, the effective sample sizes should be doubled, and the appropriate non-centrality parameter becomes  $\delta = \sqrt{2n}(\theta - f)(1-\phi)$.
Power may then be approximated using the formula in Theorem 1.


# Finite-sample corrections {#sec:finite-sample}


The result of our power calculations above are only accurate to the extend that the asymptotic approximations are applicable.
In practice, of course, we have only finite samples, and the asymptotic approximation no longer hold when cell counts are low.
While existing tools have completely ignored this issue, we offer here a simple correction in finite samples by resorting to exact tests.
Specifically, we calculate the minimum number of observations of the genetic variants needed for Fisher's exact test to be correctly calibrated, referred to as the **minimum calibration numbers**.

For a contingency table with marginal phenotype counts $(n_1, n_2)$, and marginal genetic variant counts $(m_1, m_2)$, we calculate the p-values of the most extreme observations according to Fisher's exact test.
For rare risk alleles, this corresponds to the following table.
```{r echo=FALSE}
dt <- data.frame(matrix(c("Cases", "$m_{1}$", "$n_{1}-m_{1}$", "$n_1$",
                          "Controls", "$0$", "$n_{2}$", "$n_2$"), byrow = T, nrow = 2))

colnames(dt) <- c("# Observations", "Risk allele", "Non-risk allele", "Counts by phenotype")

kable(dt, "html", escape = FALSE, align = "c") %>%
  kable_styling(bootstrap_options = c("hover", "responsive"), full_width = F) %>%
  add_header_above(c(" " = 1, "Allele variant" = 2, " " = 1))
```

If the p-values do not fall below the desired type I error threshold, then the rejection region (for $O_{11}$) must lie beyond $m_1$. 
Under the fixed marginal assumptions of Fisher's exact test, no contingency tables with the given marginals can be rejected at the specified level.
In other words, we have given up all power to achieve proper type I error control.
Therefore, the minimum counts needed for the risk allele count must exceed $m_1$, in order for association tests to have any power.

For rare non-risk alleles, the most extreme observation corresponds to the following table.
```{r echo=FALSE}
dt <- data.frame(matrix(c("Cases", "$n_{1}$", "$0$", "$n_1$",
                          "Controls", "$n_2-m_2$", "$m_{2}$", "$n_2$"), byrow = T, nrow = 2))

colnames(dt) <- c("# Observations", "Risk allele", "Non-risk allele", "Counts by phenotype")

kable(dt, "html", escape = FALSE, align = "c") %>%
  kable_styling(bootstrap_options = c("hover", "responsive"), full_width = F) %>%
  add_header_above(c(" " = 1, "Allele variant" = 2, " " = 1))
```

We can similarly determine the minimum number of non-risk allele counts needed to achieve non-zero power at the given type I error target, for a given phenotype marginals $(n_1, n_2)$.

For correctly calibrated tests, an alternative hypothesis with expected variant counts less than the minimum calibration numbers should have power close to zero; asymptotic power approximations do not apply for these alternatives.
We correct the asymptotic approximations laid out in [the first section](#sec:unified-analysis) by setting the predicted statistical power for alternatives in this "rare-variant zone" to zero.

We conduct an extensive simulation study to examine the quality of this finite-sample correction in [the last Secction](#sec:numerical).
We find this simple rule produces accurate corrections, matching up well to the simulated powers of exact tests.
In general, the correction kicks in only for small sample sizes.

In the web-based application U-PASS, we mark the "rare-variant zone" with red dashed lines in the OR-RAF diagram.
We also provide options for users to specify the rare-variant threshold by absolute number of counts, or as a fraction of the total number of subjects.
We find these two options ad-hoc; the minimum calibration numbers approach provides a more theoretically grounded approximation in power calculations for rare-variants.


# Proof of main results {#sec:proof}

We prove Theorem 1 in this section.

## Asymptotic equivalence of likelihood ratio tests and the chi-square test
The asymptotic equivalence of the likelihood ratio (LR) test and the chi-square test in 2-by-2 tables can be found in standard texts on asymptotic theory.
See, e.g., @ferguson2017course Chapter 10 and Chapter 24, and @lehmann2004elements Chapter 5; see also, @hunter2002 for an accessible derivation of the formula for the non-centrality parameter.

Recall the likelihood ratio statistic in LR test
\begin{equation*}
    LR = \frac{\sup_{\mu\in H_1}L(\mu)}{\sup_{\mu\in H_0}L(\mu)}.
\end{equation*}
where $H_0$ is the set of independent probabilities, and $H_1$ all valid 2-by-2 multinomial probabilities.
To see the asymptotic equivalence with the LR statistic under logistic regressions with binary predictors, we reparametrize the likelihood as
\begin{align*}
    L(\mu) &= \mu_{11}^{O_{11}}\mu_{12}^{O_{12}}\mu_{21}^{O_{21}}(1-\mu_{11}-\mu_{12}-\mu_{21})^{O_{22}} \\
    &= \phi^{n_1}(1-\phi)^{n_2}p_{1}^{O_{11}}(1-p_{1})^{O_{12}}p_{2}^{O_{21}}(1-p_{2})^{O_{22}}
\end{align*}
where we have omitted the multinomial coefficient.
In the latter parametrization, it is easy to show that the maximizers are $\widehat{\phi} = n_1/n$, $\widehat{p_1} = O_{11}/n_1$, and $\widehat{p_1} = O_{21}/n_2$ under the alternative, and $\widehat{\phi} = n_1/n$, $\widehat{p_1} = \widehat{p_1} = (O_{11}+O_{21})/n$ under the null.
Therefore, the terms involving $\phi$ cancels in the LR statistic, and the LR statistic coincides with the logistic regressions likelihood ratio, where $p_1$ and $p_2$ are further reparametrized as
\begin{align*}
    p_1 &= \exp{(\beta_0+\beta_1)}/(1+\exp{(\beta_0+\beta_1)}), \\
    p_2 &= \exp{(\beta_0)}/(1+\exp{\beta_0}).
\end{align*}
Hence, the logistic regressions likelihood ratio follows the same distribution as in the original likelihood ratio test.
Notice that this is not an immediate consequence of the invariance property of the likelihood ratio tests. Rather, it follows because $n_1$, $n_2$ are ancillary for inference of the odds ratios.

## Asymptotic equivalence with Welch's t-test

We now work with the two-binomial assumption, conditioning on the phenotype marginals $n_1$, $n_2$, and show that Welch's t-test has asymptotically the same power.
Recall the Welch t-statistic
\begin{equation} \label{eq:Welch-t}
    t = \frac{\widehat{p_1} - \widehat{p_2}}{\sqrt{\frac{\widehat{p_1}(1-\widehat{p_1})}{n_1} + \frac{\widehat{p_2}(1-\widehat{p_2})}{n_2}}}, \quad\quad (*)
\end{equation}
where $\widehat{p_1} = O_{11}/n_1$ and $\widehat{p_2} = O_{21}/n_2$.
By the (Lindeberg-Feller) central limit theorem, for the sequence of alternatives defined in the two-bionomial model, we have 
\begin{equation*}
    \sqrt{n_i}(\widehat{p_i} - p_i)\big/\sqrt{p_i(1-p_i)} \Rightarrow \mathrm{N}(0,1),
    \quad \text{for }\,i=1,2.
\end{equation*}
and therefore, by independence of the two binomial distributions, we have 
\begin{equation}
    t - (p_1-p_2)\Big/\sqrt{\frac{{p_1}(1-{p_1})}{n_1} + \frac{{p_2}(1-{p_2})}{n_2}} \Rightarrow \mathrm{N}(0,1). 
\end{equation}

By the definition of the alternatives in the two-bionomial model, we know that 
\begin{equation} \label{eq:center-mean}
    \sqrt{n}(p_1-p_2) \to \delta/(\phi(1-\phi)). \quad\quad (1)
\end{equation}
On the other hand, for the denominator of $(*)$, we have
\begin{align}
    &\sqrt{n}\sqrt{\frac{{p_1}(1-{p_1})}{n_1} + \frac{{p_2}(1-{p_2})}{n_2}} \sim \sqrt{\frac{{p_1}(1-{p_1})}{\phi} + \frac{{p_2}(1-{p_2})}{1-\phi}} \nonumber \\
    % &= \Bigg(\frac{(\theta + O(1/\sqrt{n}))(1-\theta + O(1/\sqrt{n}))}{\phi} \,\, + \nonumber \\  &\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad + \frac{(\theta + O(1/\sqrt{n}))(1-\theta + O(1/\sqrt{n}))}{1-\phi}\Bigg)^{1/2} \nonumber \\
    &= \Bigg(\frac{(\theta + O(1/\sqrt{n}))(1-\theta + O(1/\sqrt{n}))}{\phi} + \frac{(\theta + O(1/\sqrt{n}))(1-\theta + O(1/\sqrt{n}))}{1-\phi}\Bigg)^{1/2} \nonumber \\
    &\sim \sqrt{(\theta(1-\theta)) \Big/ (\phi(1-\phi))}. \quad\quad\quad\quad\quad\quad\quad\quad  (2)
\end{align}
Dividing Equation $(1)$ by $(2)$, we conclude that the centers of the distribution of $t$ converges to 
$$\delta\Big/\sqrt{\theta(1-\theta)\phi(1-\phi)},$$
which is precisely the square root of the non-centrality parameter in Theorem 1.
Finally, the conclusion in Theorem 1 follows from the fact that the square of a normal distribution with mean $\sqrt{\lambda}$ is equal in distribution to a chi-square distribution with non-centrality parameter $\lambda$.

# Numerical illustrations {#sec:numerical}

We examine the accuracy of the asymptotic approximations in Theorem 1 in finite samples, and of the correction by minimum calibration number introduced in [Section 2](#sec:finite-sample), via numerical simulation.

We refer readers to Section 4 in the [full Supplement](./Supplement_to_U_PASS.pdf){target="_blank"} for further details.


# References